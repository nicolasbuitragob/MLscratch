{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd89031-d291-4420-b3df-05caef72a805",
   "metadata": {},
   "source": [
    "# Class for linear models\n",
    "### Linear Regression\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7022aa9-5c5b-4cd5-a071-e05b276a185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbaaf0e5-51f2-499d-96c8-5aae980b6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.iterations = 500\n",
    "        self.learning_rate = 0.001  \n",
    "    def fit(self,X_train,y_train):\n",
    "        m,n = X.shape\n",
    "        theta = np.random.randn(n)\n",
    "        X_train_bias = np.c_[np.ones(m_train),X_train]\n",
    "        theta_with_bias = np.insert(theta,0,0)\n",
    "        cost = []\n",
    "        \n",
    "        #Loop over the number of iterations\n",
    "        for i in range(self.iterations):\n",
    "            h = np.dot(X_with_bias,theta_with_bias)\n",
    "            error = h - y_train            \n",
    "            J = (1/m_train)*np.sum(error**2)\n",
    "            grad = (2/m_train)*np.dot(X_with_bias.T,error)\n",
    "            theta_with_bias = theta_with_bias - self.learning_rate*grad\n",
    "            cost.append(J)\n",
    "         \n",
    "        #Plot the cost values\n",
    "        plt.plot(cost)\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "        \n",
    "        return theta_with_bias\n",
    "    \n",
    "    def predict(self,X_test,theta):        \n",
    "        m_test = X_test.shape[0]\n",
    "        X_test_bias = np.c_[np.ones(m_test),X_test]\n",
    "        pred = np.dot(X_test_bias,theta)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191cb248-309d-49f3-9a64-6bd98fb96144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,iterations,learning_rate):\n",
    "        self.iterations = 500\n",
    "        self.learning_rate = 0.001\n",
    "    \n",
    "    #Sigmoid function\n",
    "    def sigmoid(self,x):\n",
    "        z = 1/(1 + np.exp(-x))\n",
    "        return z\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        m,n = X.shape\n",
    "        theta = np.random.randn(n) \n",
    "        X_with_bias = np.c_[np.ones(m),X] \n",
    "        theta_with_bias = np.insert(theta,0,0)\n",
    "        \n",
    "        cost = []\n",
    "        for i in range(self.iterations):\n",
    "            h = np.dot(X_with_bias,theta_with_bias)\n",
    "            z = self.sigmoid(h)    \n",
    "            J = (-1/m)*np.sum(y*np.log(z)+(1-y)*np.log(1-z))\n",
    "            error = z - y\n",
    "            grad = (1/m)*np.dot(X_with_bias.T,error)\n",
    "            theta_with_bias =  theta_with_bias - self.learning_rate*grad\n",
    "            cost.append(J)\n",
    "            \n",
    "        plt.plot(cost)\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "        return theta_with_bias\n",
    "    \n",
    "    def predict(self,X_test,theta):\n",
    "        m_test = X_test.shape[0]\n",
    "        X_test_bias = np.c_[np.ones(m_test),X_test]\n",
    "        pred = self.sigmoid(np.dot(X_test_bias,theta))\n",
    "        return (pred >= 0.5 )*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a874ff-1b0b-4b0b-8d20-dd78f32574cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f098d2-0d10-4463-afc0-cff955ab6f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a37d7-a2f4-4f5e-bcd5-44d03bc59cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b41c45b-aedb-4938-93fb-69053027b83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c9ecf-dbf5-4fe6-9f49-5232fb1063fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76afe1-206d-4d3c-84b0-9b9af0305ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1058635-8877-4fde-8d36-a1053d01bcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee2aa8-6248-4335-b2b8-917501452f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0156f08-0a68-4142-b753-c3c6e20b3aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb69c9-4eec-4453-8fa8-66a659fa448b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
