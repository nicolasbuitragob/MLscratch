{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5140b903-0d84-4933-9887-593f9477e3ea",
   "metadata": {},
   "source": [
    "# Logistic Regression from scratch\n",
    "\n",
    "Our second model is logistic regression. In this first example we will perform a binary classification\n",
    "\n",
    "We will train the algorithm in the [titanic](https://www.kaggle.com/c/titanic) dataset from kaggle.\n",
    "\n",
    "I have already done an EDA and feature engineering so we have a ready to use dataset. More information here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33082c4d-7479-4e43-93ba-fe2294b05eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97011d02-641c-4021-9059-687530ebf2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv('train_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351ac523-9cde-4dcc-86f8-b2b8c206a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.64165</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.92500</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.55000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.86250</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1        2  3  4         5     6  11  12  13  ...  21  22  23  24  25  \\\n",
       "0    3  0   7.2500  2  0   3.62500  22.0   0   1   0  ...   0   0   0   0   0   \n",
       "1    1  0  71.2833  2  1  35.64165  38.0   1   0   1  ...   0   0   0   0   0   \n",
       "2    3  0   7.9250  1  0   7.92500  26.0   1   0   0  ...   0   0   0   0   0   \n",
       "3    1  0  53.1000  2  1  26.55000  35.0   1   0   0  ...   0   0   0   0   0   \n",
       "4    3  0   8.0500  1  0   8.05000  35.0   0   1   0  ...   0   0   0   0   0   \n",
       "..  .. ..      ... .. ..       ...   ...  ..  ..  ..  ...  ..  ..  ..  ..  ..   \n",
       "886  2  0  13.0000  1  0  13.00000  27.0   0   1   0  ...   0   0   0   0   0   \n",
       "887  1  0  30.0000  1  1  30.00000  19.0   1   0   0  ...   0   0   0   0   0   \n",
       "888  3  2  23.4500  4  0   5.86250  29.0   1   0   0  ...   0   0   0   0   0   \n",
       "889  1  0  30.0000  1  1  30.00000  26.0   0   1   1  ...   0   0   0   0   0   \n",
       "890  3  0   7.7500  1  0   7.75000  32.0   0   1   0  ...   0   0   0   0   0   \n",
       "\n",
       "     26  27  28  29  Survived  \n",
       "0     0   1   0   1         0  \n",
       "1     0   0   1   1         1  \n",
       "2     1   0   0   0         1  \n",
       "3     0   0   1   1         1  \n",
       "4     0   1   0   0         0  \n",
       "..   ..  ..  ..  ..       ...  \n",
       "886   0   1   0   0         0  \n",
       "887   1   0   0   0         1  \n",
       "888   1   0   0   1         0  \n",
       "889   0   1   0   0         1  \n",
       "890   0   1   0   0         0  \n",
       "\n",
       "[891 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e41e2a-c125-42f5-b76a-dad3dd947dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Survived']\n",
    "df.drop('Survived',inplace = True,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bce553f-2e54-45fc-8810-7e37c23ff677",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db88784-7c5f-435c-9caa-f62dc618c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e7f670-ee8f-4d2d-8299-72d9e39ac374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "243ad8ce-09ab-4ca6-b98e-bbe3dcb3a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(X_scaled,y,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f6cae-a091-411e-bc98-ba63e02e68c4",
   "metadata": {},
   "source": [
    "### Now it's time to create the model\n",
    "\n",
    "First, notation and equations that we are going to use in the code\n",
    "\n",
    "\n",
    "\n",
    "**Notation:**\n",
    "\n",
    "$\\alpha = \\text{Learning rate}$\n",
    "\n",
    "\n",
    "$\\nabla_{\\theta} = \\text{Gradient}$\n",
    "\n",
    "$m = \\text{Length of the training set}$\n",
    "\n",
    "$\\theta = \\text{Theta parameters}$\n",
    "\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672daf7e-17d0-4b4e-891b-4f24a0b7be9c",
   "metadata": {},
   "source": [
    "**Equations:**\n",
    "\n",
    "\n",
    "**Sigmoid function**\n",
    "\n",
    "$\\sigma (p) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-p}}  $ \n",
    "\n",
    "**Model prediction** \n",
    "\n",
    "$p = \\sigma(\\theta \\cdot X)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$y =\n",
    "\\begin{cases}\n",
    "  0 =\\text {if  p} \\lt 0.5\\\\\n",
    "  1 =\\text {if  p} \\geq 0.5\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "**Cost Function**\n",
    "\n",
    "$\\text {Binary cross entropy loss} = -\\frac{1}{m} \\sum_{i=1}^m[y log(p)+(1-y)log(1-p)]$\n",
    "\n",
    "**Gradient**\n",
    "\n",
    "$\\nabla_{\\theta} \\to \\frac{\\partial}{\\partial \\theta} = \\frac{1}{m}\\sum_{i=1}^m ({p - y})x$\n",
    "\n",
    "**Vectorized Gradient**\n",
    "\n",
    "$\\nabla_{\\theta}$  $ = \\frac{1}{m} \\cdot X^T (p- y)$\n",
    "\n",
    "**Update theta**\n",
    "\n",
    "$\\theta = \\theta - \\alpha \\cdot \\nabla_{\\theta}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56b92a64-4baa-4c93-87a7-74760ec8ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self,iterations,learning_rate):\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(x):\n",
    "        z = 1/(1 + np.exp(-x))\n",
    "        return z\n",
    "\n",
    "    def fit(self,X,y):\n",
    "\n",
    "        m,n = X.shape\n",
    "        theta = np.random.randn(n) # Random Initialization of theta\n",
    "\n",
    "        #add bias terms to X and theta\n",
    "        X_with_bias = np.c_[np.ones(m),X] \n",
    "        theta_with_bias = np.insert(theta,0,0)\n",
    "\n",
    "        cost = []\n",
    "        for i in range(self.iterations):\n",
    "            h = np.dot(X_with_bias,theta_with_bias)\n",
    "            z = self.sigmoid(h)    \n",
    "            J = (-1/m)*np.sum(y*np.log(z)+(1-y)*np.log(1-z))\n",
    "\n",
    "            error = z - y\n",
    "            grad = (1/m)*np.dot(X_with_bias.T,error)\n",
    "            theta_with_bias =  theta_with_bias - grad*self.learning_rate\n",
    "            cost.append(J)\n",
    "        plt.plot(cost)\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Binary cross entropy loss')\n",
    "        plt.show()\n",
    "        return theta_with_bias\n",
    "    \n",
    "    def predict(self,X_test,theta):\n",
    "        m_test = X_test.shape[0]\n",
    "\n",
    "        #Adding X0 = 1 to test set\n",
    "        X_test_bias = np.c_[np.ones(m_test),X_test]\n",
    "\n",
    "        #Calculate the prediction\n",
    "        pred = np.dot(X_test_bias,theta)\n",
    "    \n",
    "        return (pred >= 0.5 )*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d565c5c0-2b66-4e58-a8de-7befe8eb122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Sigmoid function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b60c9cf5-5cb1-48be-b346-d329eabc33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function for training data \n",
    "custom_model = logistic_regression(iterations = 2500,learning_rate = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35fa1543-53bf-40ee-bdc0-cd74b29d5199",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sigmoid() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4b09fc387a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-5ec23cd42184>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_with_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_with_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sigmoid() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "theta = custom_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d986d-f324-4e90-b76c-cab3b8baf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = custom_model.predict(X_test,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affbdd3b-3e09-4ef1-96cb-1d4820a08acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db077c3f-392b-40c1-af97-92dde93d41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(X_train,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcda56-1733-42dd-b267-3d063f0256e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a9dd79-caad-4295-87b4-249b1dfa65bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53d28e-5295-422d-90d1-8c65de77ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ebcf30-fca5-452b-989a-e93172f96109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c6d86-8431-4a21-8fad-6d7dc8d1a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6277898-e8a6-44c2-b46b-54131ac78edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_model = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4668714-5800-484a-9974-fc7e9f21811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06779d-86b2-406b-b6e3-cba96c2057c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8db1d2-06c6-4e98-8e3d-5fb685132645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6e944-e2d3-4759-b15e-40ea63e039ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c194a74-a1e1-4b66-89b9-9c199d9ed7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcadb04-2974-48f5-8936-49a84171bebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ce21c-0ca9-47d7-9739-657f20782dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398170b3-8c30-4d82-9efd-60f46a4980da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71619a-91d5-4ffd-9eee-a21c33e4da3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0d8ce-2f5e-4d0f-8fc8-5a11d7198fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5cce5-1fc0-4c94-bfdf-e6793872cfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
